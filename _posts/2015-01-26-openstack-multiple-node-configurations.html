---
layout: post
title: OpenStack Multiple Node Configurations
date: 2015-01-26 14:02:24.000000000 -08:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories: []
tags:
- KVM
- Linux
- OpenStack
- Red Hat
meta:
  _edit_last: '63054820'
  geo_public: '0'
  _publicize_job_id: '14430844427'
  _wpas_skip_9542380: '1'
  publicize_linkedin_url: https://www.linkedin.com/updates?discuss=&scope=329229505&stype=M&topic=5965478662701613057&type=U&a=ZV_3
  _wpas_done_9468659: '1'
  _publicize_done_external: a:1:{s:8:"linkedin";a:1:{s:10:"pzvfqtzaYA";b:1;}}
  _wpas_skip_9468659: '1'
  _oembed_72beeb908867782e6438a330166da0c3: "{{unknown}}"
  _oembed_a79876e563f7a6f249382277715854b7: "{{unknown}}"
  _oembed_76d93234bc1fad3c755f060982f272cc: "{{unknown}}"
  _oembed_9eb02dd37afe298b22593464fc7dc69a: "{{unknown}}"
  _oembed_6109603f83493002b33fcea8845b398e: "{{unknown}}"
  _oembed_bde70500c76c3c64f033961d46337815: "{{unknown}}"
  _oembed_98a48f9eac1dae13a55e93d226117c9d: "{{unknown}}"
  _oembed_8cba39ecdb9fc6d48bd75b3dcf4cd34b: "{{unknown}}"
  _oembed_96b2a8cab13d5a8ef42e87eb5e53573f: "{{unknown}}"
  _oembed_4208c915a1a003d9784066593c29fbdd: "{{unknown}}"
  _oembed_a2064a0848029571df1ea0b9e129f587: "{{unknown}}"
  _oembed_9ae4931216fc3cba6563084f14ae2897: "{{unknown}}"
  _oembed_ba664c2d1079fa3499ca3b998e4c149c: "{{unknown}}"
  _oembed_f487c8b274400647a6a6f648bebd184c: "{{unknown}}"
  _oembed_721f516d566c33be7548646009c331dd: "{{unknown}}"
  _oembed_edbd5da2ed33739722950662162b9d9f: "{{unknown}}"
  _oembed_b42843c87ae5ffe449bcdab9ea9cf30b: "{{unknown}}"
  _oembed_18a8e5688efb0226e3a6525f8ac641e9: "{{unknown}}"
  _oembed_a3e3d388667a27dba115197a8eb93ad4: "{{unknown}}"
  _oembed_46c980652b757a2ac930b5fb14ada822: "{{unknown}}"
  _oembed_84b909d1d004710045c3a2f206eed596: "{{unknown}}"
  _oembed_d448b4b85c5b5b0cdeefd3e9be9c090a: "{{unknown}}"
  _oembed_a26f8cec8b8b1fcfa37e3824cad84983: "{{unknown}}"
  _oembed_9dd050398ad685e08acb7faf5a7da233: "{{unknown}}"
  _oembed_cd89ebb23bf1c0ab14206d501b1c06b4: "{{unknown}}"
  _oembed_b6cb2d9ef98a321bf28b04d1160807cd: "{{unknown}}"
  _oembed_a5369c4faa4014eb151cc3677f7806af: "{{unknown}}"
  _oembed_d7347f70397c9f63db2c21eaa0131b0b: "{{unknown}}"
  _oembed_4885976b7bd330bdcc13450c3ebc8f52: "{{unknown}}"
  _oembed_6189d1c02f1dbe9418c446c1f513ff3e: "{{unknown}}"
  _oembed_0b5dd0e9b40b2d8646bd36d22c9bec49: "{{unknown}}"
  _oembed_e5e19f58900b5f503d56b4b2e5ec947a: "{{unknown}}"
  _oembed_3952ea234c4307fe3afeb1ea33b5a371: "{{unknown}}"
author:
  login: ktenzer1
  email: keith.tenzer@gmail.com
  display_name: ktenzer
  first_name: ''
  last_name: ''
permalink: "/2015/01/26/openstack-multiple-node-configurations/"
---
<h3>Node Types</h3>
<p>OpenStack can be deployed in a single-node or multi-node configuration. For the purpose of this post I am going to assume you understand OpenStack basics and have at least done a basic installation on a single-node using RDO or another installer. <!--more--> If not please refer to this <a href="http://keithtenzer.com/2014/12/05/creating-storage-services-in-openstack-on-netapp-part-i-of-iii/">post </a>which covers the basics. OpenStack is of course a culmination of loosely coupled projects that define services. A node is nothing more than a grouping of OpenStack services that run on bare-metal, in a container or virtual machine. The purpose of a node is to provide horizontal scaling and HA. There are four possible node types in OpenStack: controller, compute, network and storage.</p>
<h4>Controller Node</h4>
<p>The controller node is the control plane for the OpenStack environment. The control pane handles identity (<a href="https://wiki.openstack.org/wiki/Keystone">keystone</a>), dashboard (<a href="https://wiki.openstack.org/wiki/Horizon">Horizon</a>), telemetry (<a href="https://wiki.openstack.org/wiki/Ceilometer">ceilometer</a>), orchestration (<a href="https://wiki.openstack.org/wiki/Heat">heat</a>) and network server service (<a href="https://wiki.openstack.org/wiki/Neutron">neutron</a>).</p>
<h4>Compute Node</h4>
<p>The compute node runs a hypervisor (KVM, ESX, Hyper-V or XenServer). The compute node handles compute service (<a href="https://wiki.openstack.org/wiki/Nova">nova</a>), telemetry (<a href="https://wiki.openstack.org/wiki/Ceilometer">ceilometer</a>) and network Open vSwitch agent service (<a href="https://wiki.openstack.org/wiki/Neutron">neutron</a>).</p>
<h4>Network Node</h4>
<p>The network node runs networking services (<a href="https://wiki.openstack.org/wiki/Neutron">neutron</a>). It runs the neutron services for L3, metadata, DHCP and Open vSwitch. The network node handles all networking between other nodes as well as tenant networking and routing. It provides services such as DHCP and floating IPs that allow instances to connect to public networks. Neutron sits on top of <a href="http://openvswitch.org/">Open vSwitch</a> using either the ml2 or openvswitch plugin. Using Open vSwitch Neutron builds three network bridges: br-int, br-tun and br-ex. The br-int bridge connects all instances. The br-tun bridge connects instances to the physical NIC of the hypervisor. The br-ex bridge connects instances to external (public) networks using floating IPs. Both the br-tun and br-int bridges are visible on compute and network nodes. The br-ex bridge is only visible on network nodes.</p>
<h4>Storage Node</h4>
<p>The storage node runs storage services. It handles image service (<a href="https://wiki.openstack.org/wiki/Glance">glance</a>), block storage (<a href="https://wiki.openstack.org/wiki/Cinder">cinder</a>), object storage (<a href="https://wiki.openstack.org/wiki/Swift">swift</a>) and in the future shared file storage (<a href="https://wiki.openstack.org/wiki/Manila">manila</a>). Typically a storage node would run one type of storage service: object, block or file. Glance should run on nodes providing storage services for images (Cinder or Swift). Glance typically benefits from running on same node as its backing storage service. NetApp for example provides a storage backend that allows images to be cloned using the NetApp storage backend instead of the network.</p>
<h3>Multi-node Configurations</h3>
<p>While single-node configurations are acceptable for small environments, testing or POCs most production environments will require a multi-node configuration for various reasons. As mentioned multi-node configurations group similar OpenStack services and provide scalability as well as the possibility for high availability. One of the great things about OpenStack is the architecture. Every service is decoupled and all communication between services is done through RESTful API endpoints. This is the model architecture for cloud. The advantages are that we have tremendous flexibility in how to build a multi-node configuration. While a few standards have emerged there are many more possible variations and in the end we are not stuck to a rigid deployment model. The standards for deploying multi-node OpenStack are as a two-node, three-node or four-node configuration.</p>
<h4>Two-node OpenStack Configuration</h4>
<p>The two-node configuration has a controller and compute node. Here we can easily scale-out compute nodes. Most likely we would run just one controller node or we could setup an active / passive HA configuration for the controller node using <a href="http://clusterlabs.org/">Pacemaker</a>. Below is an illustration of a two-node OpenStack configuration:</p>
<p><a href="https://keithtenzer.files.wordpress.com/2015/01/openstack_multinode_2_architecture.jpg"><img class=" wp-image-546 aligncenter" src="{{ site.baseurl }}/assets/2015/01/openstack_multinode_2_architecture.jpg?w=300" alt="openstack_multinode_2_architecture" width="692" height="397" /></a></p>
<h4>Three-node OpenStack Configuration</h4>
<p>The three-node configuration has a controller, compute and network node. Here we can easily scale-out compute or network nodes. Most likely we would run just one controller node or we could setup an active / passive HA configuration for the controller node using <a href="http://clusterlabs.org/">Pacemaker</a>. In addition we could also setup active / passive configuration for network node to achieve HA and horizontal scaling depending on resource requirements. Below is an illustration of a three-node OpenStack configuration:</p>
<p><a href="https://keithtenzer.files.wordpress.com/2015/01/openstack_multinode_3_architecture1.jpg"><img class=" wp-image-547 aligncenter" src="{{ site.baseurl }}/assets/2015/01/openstack_multinode_3_architecture1.jpg?w=300" alt="openstack_multinode_3_architecture" width="678" height="389" /></a></p>
<h4>Four-node OpenStack Configuration</h4>
<p>The four-node configuration has a controller, compute, network and storage node. Here we can easily scale-out compute, network and storage nodes. Most likely we would run just one controller node or we could setup an active / passive HA configuration for the controller node using <a href="http://clusterlabs.org/">Pacemaker</a>. In addition we could also setup active / passive configuration for network and storage nodes to achieve HA as well as horizontal scaling depending on resource requirements. Below is an illustration of a four-node OpenStack configuration:</p>
<p><a href="https://keithtenzer.files.wordpress.com/2015/01/openstack_multinode_4_architecture.jpg"><img class=" wp-image-548 aligncenter" src="{{ site.baseurl }}/assets/2015/01/openstack_multinode_4_architecture.jpg?w=300" alt="openstack_multinode_4_architecture" width="658" height="342" /></a></p>
<h3>Three-node OpenStack Installation</h3>
<p>Before we start the installation we will need to provision three nodes running RHEL (Red Hat Enterprise Linux). The nodes can be bare-metal, containers or virtual machines. In my environment I created three virtual machines running RHEL 7 under RHEV 3.4 (Red Hat Enterprise Virtualization). If you are interested in how to setup RHEV you can get more information <a href="http://keithtenzer.com/2015/01/05/red-hat-enterprise-virtualization-rhev-home-lab-configuration/">here</a>. Below are the steps to deploy a three-node OpenStack installation using RHEL 7 and latest Red Hat OpenStack distribution:</p>
<h4>Steps to preform on each node</h4>
<ul>
<li>Install RHEL 7 and enable one NIC interface (eth0)</li>
<li>Register subscription</li>
<li>
<pre>#subscription-manager register</pre>
</li>
</ul>
<ul>
<li>List available subscriptions</li>
<li>
<pre>#subscription-manager list --available</pre>
</li>
<li>Attach a specific subscription (the pool id is listed in above command)</li>
</ul>
<ul>
<li>
<pre>#subscription-manager attach --pool=8a85f9814a7ea2ec014a813b19433cc8</pre>
</li>
<li>Clear existing repositories and enable correct ones to grab latest Red Hat OpenStack distro</li>
</ul>
<ul>
<li>
<pre>#subscription-manager repos --disable=*</pre>
</li>
</ul>
<ul>
<li>
<pre>#subscription-manager repos --enable=rhel-7-server-rpms</pre>
</li>
<li>
<pre>#subscription-manager repos --enable=rhel-7-server-optional-rpms</pre>
</li>
<li>
<pre>#subscription-manager repos --enable=rhel-7-server-openstack-5.0-rpms</pre>
</li>
</ul>
<p>or</p>
<ul>
<li>
<pre>#<code>subscription-manager repos --enable=rhel-7-server-openstack-6.0-rpms</code></pre>
</li>
<li>Install required packages</li>
</ul>
<ul>
<li>
<pre>#yum install -y yum-plugin-priorities yum-utils</pre>
</li>
</ul>
<ul>
<li>
<pre>#yum-config-manager --setopt=”rhel-7-server-openstack-5.0-rpms.priority=1” --enable rhel-7-server-openstack-5.0-rpms</pre>
</li>
</ul>
<p>or</p>
<ul>
<li>
<pre>#<code>yum-config-manager --setopt=”rhel-7-server-openstack-6.0-rpms.priority=1” --enable rhel-7-server-openstack-6.0-rpms</code></pre>
</li>
<li>
<pre>#yum update -y</pre>
</li>
</ul>
<ul>
<li>
<pre>#yum install -y openstack-packstack</pre>
</li>
</ul>
<ul>
<li>Setup hostname</li>
</ul>
<ul>
<li>
<pre>#hostname ostack-ctr.openstack</pre>
</li>
</ul>
<ul>
<li>
<pre>#vi /etc/hostname</pre>
</li>
<li>
<pre>ostack-ctr.openstack</pre>
</li>
</ul>
<ul>
<li>
<pre>#vi /etc/sysconfig/network</pre>
</li>
</ul>
<ul>
<li>
<pre>HOSTNAME=ostack-ctr.openstack
GATEWAY=192.168.2.1</pre>
</li>
</ul>
<ul>
<li>Setup hosts file if DNS resolution is not configured</li>
</ul>
<ul>
<li>
<pre>#vi /etc/hosts</pre>
</li>
</ul>
<ul>
<li>
<pre>127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4
::1 localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.2.205 ostack-ctr ostack-ctr.openstack
192.168.2.206 ostack-cmp ostack-cmp.openstack
192.168.2.207 ostack-net ostack-net.openstack</pre>
</li>
<li>Configure eth0 network interface</li>
</ul>
<ul>
<li>
<pre>#vi /etc/sysconfig/network-scripts/ifcfg-eth0</pre>
</li>
</ul>
<ul>
<li>
<pre>TYPE=Ethernet
BOOTPROTO=none
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=no
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_PEERDNS=yes
IPV6_PEERROUTES=yes
IPV6_FAILURE_FATAL=no
NAME=eth0
UUID=6c53462f-f735-48c0-ae85-c0ec61a53688
ONBOOT=yes
HWADDR=00:1A:4A:DE:DB:CC
IPADDR0=192.168.2.205
PREFIX0=24
GATEWAY0=192.168.2.1
DNS1=192.168.2.1
NM_CONTROLLED=no</pre>
</li>
</ul>
<p>Note: ensure you set the MAC address (HWADDR) correctly. You can find the MAC address using the "ip a" command.</p>
<ul>
<li>Disable Network Manager</li>
</ul>
<ul>
<li>
<pre>#systemctl disable NetworkManager</pre>
</li>
<li>reboot node</li>
</ul>
<h4>Steps to perform on controller node</h4>
<ul>
<li>Generate the default answers file</li>
<li>
<pre><span style="font-family:Monaco, Consolas, 'Andale Mono', 'DejaVu Sans Mono', monospace;"><span style="font-size:14px;line-height:normal;">#packstack --gen-answer-file=/root/answer_file.txt</span></span></pre>
</li>
<li>Update the following in answers file</li>
</ul>
<ul>
<li>
<pre>CONFIG_CONTROLLER_HOSTS=192.168.2.205
CONFIG_COMPUTE_HOSTS=192.168.2.206
CONFIG_NETWORK_HOSTS=192.168.2.207
CONFIG_STORAGE_HOST=192.168.2.205
CONFIG_HORIZON_SSL=y
CONFIG_PROVISION_DEMO=n</pre>
</li>
<li>Install OpenStack using packstack answers file</li>
</ul>
<ul>
<li>
<pre><span style="font-family:Monaco, Consolas, 'Andale Mono', 'DejaVu Sans Mono', monospace;"><span style="font-size:14px;line-height:normal;">#packstack --answer-file=</span></span>/root/answer_file.txt</pre>
</li>
</ul>
<h3>Network Node Configuration</h3>
<p>In order to connect a existing physical network, eth0 must be added as a port to the Open vSwitch br-ex bridge. The below steps should be preformed on the network node:</p>
<ul>
<li>Update network config for eth0</li>
<li>
<pre>#vi /etc/sysconfig/network-scripts/ifcfg-eth0</pre>
<pre>DEVICE=eth0
HWADDR=00:1A:4A:DE:DB:9C
TYPE=OVSPort
DEVICETYPE=ovs
OVS_BRIDGE=br-ex
ONBOOT=yes</pre>
</li>
</ul>
<p>Note: ensure that the MAC address (HWADDR) is correct</p>
<ul>
<li>Update network config for br-ex</li>
<li>
<pre>#vi /etc/sysconfig/network-scripts/ifcfg-br-ex</pre>
</li>
</ul>
<ul>
<li>
<pre>DEVICE=br-ex
DEVICETYPE=ovs
TYPE=OVSBridge
BOOTPROTO=static
IPADDR=192.168.2.207
NETMASK=255.255.255.0
GATEWAY=192.168.2.1
DNS1=192.168.2.1
ONBOOT=yes</pre>
</li>
</ul>
<ul>
<li>Add eth0 to br-ex bridge and restart networking</li>
</ul>
<ul>
<li>
<pre>#ovs-vsctl add-port br-ex eth0 ; systemctl restart network.service</pre>
</li>
</ul>
<ul>
<li>Verify Open vSwitch configuration on network node (eth0 should be connected to br-ex)</li>
<li>
<pre>#ovs-vsctl show
348cc676-f177-4ee3-a522-8f02aeb4dcd6
 Bridge br-int
    fail_mode: secure
    Port br-int
       Interface br-int
          type: internal
 Bridge br-tun
    Port patch-int
       Interface patch-int
          type: patch
          options: {peer=patch-tun}
    Port "gre-1"
       Interface "gre-1"
          type: gre
          options: {in_key=flow, local_ip="192.168.2.207", out_key=flow, remote_ip="192.168.2.206"}
    Port br-tun
       Interface br-tun
          type: internal
 Bridge br-ex
    Port "eth0"
       Interface "eth0"
    Port br-ex
       Interface br-ex
       type: internal
 ovs_version: "2.1.3"</pre>
</li>
</ul>
<h3>Networking Configuration</h3>
<p>Public networks allow instances to connect to existing external networks. This is achieved by allocating floating IPs  from existing external networks that are shared across tenants. Private networks are tenant networks that provide complete isolation to all instances within a tenant.</p>
<h4>Create Private Network</h4>
<ul>
<li>
<pre>#neutron net-create private</pre>
</li>
</ul>
<ul>
<li>
<pre>#neutron subnet-create private 10.0.0.0/24 --name private_subnet</pre>
</li>
</ul>
<h4>Create Public Network</h4>
<ul>
<li>
<pre class="screen">#neutron net-create public --shared --router:external=True</pre>
</li>
</ul>
<ul>
<li>
<pre>#neutron subnet-create public 192.168.2.0/24 --name public_subnet --enable_dhcp=False --allocation-pool start=192.168.2.220,end=192.168.2.240 --gateway=192.168.2.1</pre>
</li>
</ul>
<h4>Create Router</h4>
<ul>
<li>
<pre>#neutron router-create router1</pre>
</li>
</ul>
<ul>
<li>
<pre>#neutron router-interface-add router1 private</pre>
</li>
</ul>
<ul>
<li>
<pre>#neutron router-gateway-set router1 public</pre>
</li>
</ul>
<p>Note: make sure you source the /root/keystonerc_admin file otherwise neutron commands will not work</p>
<p>Once we have created the private and public networks we should see the below network topology. In addition we can connect instances to just the private network or both by allocating a floating IP.</p>
<p><img class=" wp-image-321 aligncenter" src="{{ site.baseurl }}/assets/2015/01/openstack_router.jpg?w=300" alt="openstack_router" width="714" height="395" /></p>
<h3>Summary</h3>
<p>This guide covered the very basics of multi-node OpenStack deployments and networking. From here hopefully you should be able to deploy your own OpenStack multi-node configurations using Red Hat RDO. I really recommend setting up multi-node environments, it is the best way to understand and learn how the different OpenStack projects interact with one another. In addition if you would like to do everything from scratch without RDO or another distro you can follow the complete manual guide <a href="http://docs.openstack.org/juno/install-guide/install/yum/content/">here</a>. I hope this guide has been interesting and useful. I always appreciate commends and feedback so please leave some.</p>
<p>Happy Stacking!</p>
<p>(c) 2015 Keith Tenzer</p>
