I"ÿ8<h2><img class="alignnone size-full wp-image-9500" src="/assets/2017/04/tripleo_owl.png" alt="tripleo_owl" width="1024" height="350" /></h2>
<h2>Overview</h2>
<p>In this article we will setup an OpenStack environment based off Newton using the Red Hat OpenStack Platform. OpenStack is OpenStack but every distribution differs in what capabilities or technologies are supported and how OpenStack is installed, configured as well as upgraded.</p>
<p>The Red Hat OpenStack Platform uses OpenStack director based on the TripleO (<strong>O</strong>penStack <strong>o</strong>n <strong>O</strong>penStack) project to install, configure and update OpenStack. Director is a lifecycle management tool for OpenStack. Red Hat's approach is to make OpenStack easy to manage, without compromising on the "Open" part of OpenStack. If management of OpenStack can be simpler and the learning curve brought down then it has a real chance to be the next-gen virtualization platform. What company wouldn't want to be able to consume their internal IT resources like using AWS, GCE or Azure if they didn't give up anything to do so? We aren't there yet but Red Hat is making bold strides and as you will see in this article, is on a journey to make OpenStack consumable for everyone!</p>
<p><!--more--></p>
<h2>Red Hat OpenStack Platform</h2>
<p>The Red Hat OpenStack platform uses director to build, manage and upgrade Red Hat OpenStack. Director is in fact a minimal OpenStack deployment itself, with everything needed to deploy OpenStack. The main piece outside of the OpenStack core (Nova, Neutron, Glance, Swift and Heat) is Ironic. The Ironic project is focused on baremetal-as-a-service.</p>
<p>Director allows you to add physical nodes to Ironic and assign them OpenStack roles: compute, control, storage, network, etc. Once roles are assigned an OpenStack environment can be deployed, upgraded and even scaled. As mentioned director is a complete life-cycle management tool that uses OpenStack to manage OpenStack.</p>
<p>In this article we will deploy director (undercloud) on a single VM. We will add three baremetal nodes (VMs) and then deploy OpenStack (overcloud) in a minimal configuration (1 controller node and 1 compute node). I am able to run this on a laptop with just 12GB RAM.</p>
<h2>Lab Environment</h2>
<p>My idea for this configuration was build the most minimal OpenStack environment possible, something that would run on my laptop with just 12GB RAM using Red Hat OpenStack Director. In the end this experiment was successful and the configuration used is as follows:</p>
<ul>
<li><strong>KVM Hypervisor Physical Laptop:</strong>Â RHEL 7.3, CentOS or Fedora, Dual core, 12 GB RAM and 250GB disk</li>
<li><strong>Undercloud VM: </strong>RHEL 7.3, 2x vCPUs, 4GB RAM, 1 x NIC 8(provisioning), 1 x NIC (external) and 40GB disk</li>
<li><strong>Overcloud Controller VM:</strong>Â RHEL 7.3, 2 x vCPUs, 6GB RAM, 1 x NIC (provisioning), 2 x NICs (external) and 30GB disk</li>
<li><strong>Overcloud Compute VM:</strong>Â RHEL 7.3, 2 x vCPU, 4GB RAM, 1 x NIC (provisioning), 2 x NICs (external) and 20GB disk</li>
</ul>
<p><img class="alignnone size-full wp-image-9473" src="/assets/2017/04/osp_8_lab_network_setup2.png" alt="osp_8_lab_network_setup2" width="440" height="255" /></p>
<h2>Networking Setup</h2>
<p>In this configuration we are using virtual networks provided by the hypervisor host (my laptop). Create provisioningÂ and externalÂ networks on KVM Hypervisor host. Ensure that NAT forwarding is enabled and DHCP is disabled on the externalÂ network. We run OpenStack overcloud on the external network. The provisioning network should be non-routable and DHCP disabled. The undercloud will handle DHCP services for the provisioning network and other IPs will be staticallyÂ assigned.</p>
<p><strong>[Hypervisor]</strong></p>
<p>Create external network for the overcloud.</p>
<pre>[ktenzer@ktenzer ~]$Â cat &gt; /tmp/external.xml &lt;&lt;EOF
&lt;network&gt;
   &lt;name&gt;external&lt;/name&gt;
   &lt;forward mode='nat'&gt;
      &lt;nat&gt; &lt;port start='1024' end='65535'/&gt;
      &lt;/nat&gt;
   &lt;/forward&gt;
   &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;
   &lt;/ip&gt;
&lt;/network&gt;
</pre>
<p>Note: hypervisor is 192.168.122.1 and reachable via this IP from undercloud.</p>
<pre>[ktenzer@ktenzer ~]$ sudo virsh net-define /tmp/external.xml
[ktenzer@ktenzer ~]$ sudo virsh net-autostart external
[ktenzer@ktenzer ~]$ sudo virsh net-start external</pre>
<p>Create provisioning network for undercloud.</p>
<p>Note: gateway is 192.168.126.254 as we will use 192.168.126.1 as IP for the VM running our undercloud.</p>
<pre>[ktenzer@ktenzer ~]$Â cat &gt; /tmp/provisioning.xml &lt;&lt;EOF
&lt;network&gt;
   &lt;name&gt;provisioning&lt;/name&gt;
   &lt;ip address='192.168.126.254' netmask='255.255.255.0'&gt;
   &lt;/ip&gt;
&lt;/network&gt;</pre>
<pre>[ktenzer@ktenzer ~]$ sudo virsh net-define /tmp/provisioning.xml
[ktenzer@ktenzer ~]$ sudo virsh net-autostart provisioning
[ktenzer@ktenzer ~]$ sudo virsh net-start provisioning</pre>
<h2>Deploy Undercloud</h2>
<p>First install Red Hat Enterprise Linux (RHEL) 7.3 on undercloud VM. Register with subscription manager and configure required RPM repositories for Red Hat OpenStack Platform.</p>
<p><strong>[Undercloud]</strong></p>
<pre class="screen">[root@director ~]# subscription-manager register</pre>
<pre class="screen">[root@director ~]#subscription-manager list --available \
subscription-manager attach --pool=</pre>
<pre class="screen">[root@director ~]# subscription-manager repos --disable=*</pre>
<pre class="screen">[root@director ~]# subscription-manager repos --enable=rhel-7-server-rpms \
--enable=rhel-7-server-extras-rpms \ 
--enable=rhel-7-server-rh-common-rpms \ 
--enable=rhel-ha-for-rhel-7-server-rpms \ 
--enable=rhel-7-server-openstack-10-rpms</pre>
<p>Update all pacakges and reboot.</p>
<pre class="screen">[root@director ~]# yum update -y</pre>
<pre class="screen">[root@director ~]# systemctl reboot</pre>
<p>Install Director Packages.</p>
<pre class="screen">[root@director ~]# yum install -y python-tripleoclient</pre>
<p>Ensure host is defined in /etc/hosts.</p>
<pre class="screen">[root@director ~]# vi /etc/hosts 
192.168.122.90 ospd.lab.com ospd</pre>
<p>Create Stack User.</p>
<pre class="screen">[root@director ~]# useradd stack
[root@director ~]# passwd stack  # specify a password</pre>
<p>Configure user with sudo permissions.</p>
<pre class="screen">[root@director ~]# echo "stack ALL=(root) NOPASSWD:ALL" | tee -a /etc/sudoers.d/stack
[root@director ~]# chmod 0440 /etc/sudoers.d/stack</pre>
<p>Switch toÂ new stack user.</p>
<pre class="screen">[root@director ~]# su - stack
[stack@director ~]$</pre>
<p>Create directories for images and templates. Images are used to boot initial systems and provide baseline OS. Templates are used to customize deployment.</p>
<pre class="screen">[stack@director ~]$ mkdir ~/images</pre>
<pre class="screen">[stack@director ~]$ mkdir ~/templates</pre>
<p>Configure Director using the sample.</p>
<pre class="screen">[stack@director ~]$ cp /usr/share/instack-undercloud/undercloud.conf.sample \
~/undercloud.conf</pre>
<p>In my environment the 192.168.126.0/24 network isÂ the undercloud network and used for provisioning as well as deploying the overcloud.</p>
<pre class="screen">[stack@undercloud ~]$ vi ~/undercloud.conf
 [DEFAULT]
 local_ip = 192.168.126.1/24
 undercloud_public_vip = 192.168.126.2
 undercloud_admin_vip = 192.168.126.3
 local_interface = eth1
 masquerade_network = 192.168.126.0/24
 dhcp_start = 192.168.126.100
 dhcp_end = 192.168.126.150
 network_cidr = 192.168.126.0/24
 network_gateway = 192.168.126.1
 inspection_iprange = 192.168.126.130,192.168.126.99
 generate_service_certificate = true
 certificate_generation_ca = local</pre>
<p>Install the undercloud.</p>
<pre>[stack@odpd ~]$ openstack undercloud install
#############################################################################
 Undercloud install complete.
The file containing this installation's passwords is at
 /home/stack/undercloud-passwords.conf.
There is also a stackrc file at /home/stack/stackrc.
These files are needed to interact with the OpenStack services, and should be
 secured.
#############################################################################</pre>
<p>Import overcloud images.</p>
<pre>[stack@odpd ~]$ source stackrc</pre>
<pre>[stack@odpd ~]$ sudo yum install -y \
rhosp-director-images rhosp-director-images-ipa</pre>
<pre>[stack@odpd ~]$ cd ~/images $ for i in \
/usr/share/rhosp-director-images/overcloud-full-latest-10.0.tar \
/usr/share/rhosp-director-images/ironic-python-agent-latest-10.0.tar; \
do tar -xvf $i; done</pre>
<pre>[stack@odpd ~]$ openstack overcloud image upload --image-path \
/home/stack/images/</pre>
<p>Configure DNS on undercloud network.</p>
<pre class="screen">[stack@odpd ~]$ neutron subnet-list
+--------------------------------------+------+------------------+--------------------------------------------------------+
| id | name | cidr | allocation_pools |
+--------------------------------------+------+------------------+--------------------------------------------------------+
| 294ff536-dc8b-49a3-8327-62d9792d30a6 | | 192.168.126.0/24 | {"start": "192.168.126.100", "end": "192.168.126.200"} |
+--------------------------------------+------+------------------+--------------------------------------------------------+</pre>
<pre>[stack@odpd ~]$ neutron subnet-update 294ff536-dc8b-49a3-8327-62d9792d30a6 \
--dns-nameserver 8.8.8.8</pre>
<p><strong>[Hypervisor]</strong></p>
<p>Registering Overcloud Nodes. Create VM hulls in KVM using virsh on hypervisor host.</p>
<p>Note: You will need to change the disk path to suit your needs.</p>
<pre>ktenzer$ cd /home/ktenzer/VirtualMachines
ktenzer$ sudo for i in {1..3}; do qemu-img create -f qcow2 -o preallocation=metadata overcloud-node$i.qcow2 60G; done
ktenzer$ sudo for i in {1..3}; do virt-install --ram 4096 --vcpus 4 --os-variant rhel7 --disk path=/home/ktenzer/VirtualMachines/overcloud-node$i.qcow2,device=disk,bus=virtio,format=qcow2 --noautoconsole --vnc --network network:provisioning --network network:external --network network:external --name overcloud-node$i --cpu SandyBridge,+vmx --dry-run --print-xml &gt; /tmp/overcloud-node$i.xml; virsh define --file /tmp/overcloud-node$i.xml; done</pre>
<p><strong>[Undercloud]</strong></p>
<p>Copy ssh key from undercloud system to KVM hypervisor host for stack user.</p>
<pre>[stack@odpd ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub stack@192.168.122.1</pre>
<p>Save the MAC addresses of the NICs used for provisioning.</p>
<p>Note: Ironic needs to know what MAC addresses a node has associated for provisioning network.</p>
<pre class="screen">[stack@odpd images]$ for i in {1..3}; do virsh \
-c qemu+ssh://stack@192.168.122.1/system domiflist overcloud-node$i \
| awk '$3 == "provisioning" {print $5};'; done &gt; /tmp/nodes.txt</pre>
<pre class="screen">[stack@odpd images]$ cat /tmp/nodes.txt 
52:54:00:7e:d8:01
52:54:00:f6:a6:73
52:54:00:c9:b2:84</pre>
<pre class="screen">[stack@undercloud ~]$ jq . &lt;&lt; EOF &gt; ~/instackenv.json
{
  "ssh-user": "stack",
  "ssh-key": "$(cat ~/.ssh/id_rsa)",
  "power_manager": "nova.virt.baremetal.virtual_power_driver.VirtualPowerManager",
  "host-ip": "192.168.122.1",
  "arch": "x86_64",
  "nodes": [
    {
      "pm_addr": "192.168.122.1",
      "pm_password": "$(cat ~/.ssh/id_rsa)",
      "pm_type": "pxe_ssh",
      "mac": [
        "$(sed -n 1p /tmp/nodes.txt)"
      ],
      "cpu": "2",
      "memory": "4096",
      "disk": "60",
      "arch": "x86_64",
      "pm_user": "stack"
    },
    {
      "pm_addr": "192.168.122.1",
      "pm_password": "$(cat ~/.ssh/id_rsa)",
      "pm_type": "pxe_ssh",
      "mac": [
        "$(sed -n 2p /tmp/nodes.txt)"
      ],
      "cpu": "4",
      "memory": "2048",
      "disk": "60",
      "arch": "x86_64",
      "pm_user": "stack"
    },
    {
      "pm_addr": "192.168.122.1",
      "pm_password": "$(cat ~/.ssh/id_rsa)",
      "pm_type": "pxe_ssh",
      "mac": [
        "$(sed -n 3p /tmp/nodes.txt)"
      ],
      "cpu": "4",
      "memory": "2048",
      "disk": "60",
      "arch": "x86_64",
      "pm_user": "stack"
    }
  ] 
} 
EOF</pre>
<p>Validate introspection configuration.</p>
<pre>[stack@odpd ~]$ curl -O 
https://raw.githubusercontent.com/rthallisey/clapper/master/instackenv-validator.py</pre>
<p>Import nodes into Ironic and set them to bootable.</p>
<pre>[stack@odpd ~]$ openstack baremetal import --json ~/instackenv.json</pre>
<pre>[stack@odpd ~]$ openstack baremetal configure boot</pre>
<pre>[stack@odpd ~]$ openstack baremetal node list
 +--------------------------------------+------+---------------+-------------+--------------------+-------------+
 | UUID | Name | Instance UUID | Power State | Provisioning State | Maintenance |
 +--------------------------------------+------+---------------+-------------+--------------------+-------------+
 | ea61b158-9cbd-46d2-93e9-eadaccb1589b | None | None | power off | available | False |
 | 11aaf849-361e-4bda-81f5-74c245f554af | None | None | power off | available | False |
 | 275448c1-aa8d-4854-bb3b-bc73e1e1a794 | None | None | power off | available | False |
 +--------------------------------------+------+---------------+-------------+--------------------+-------------+</pre>
<p>Set nodes to managed.</p>
<pre>[stack@odpd ~]$ for node in $(openstack baremetal node list -c UUID \
-f value) ; do openstack baremetal node manage $node ; done</pre>
<p>List nodes.</p>
<pre>[stack@odpd ~]$ openstack baremetal node list
 +--------------------------------------+------+---------------+-------------+--------------------+-------------+
 | UUID | Name | Instance UUID | Power State | Provisioning State | Maintenance |
 +--------------------------------------+------+---------------+-------------+--------------------+-------------+
 | ea61b158-9cbd-46d2-93e9-eadaccb1589b | None | None | power off | manageable | False |
 | 11aaf849-361e-4bda-81f5-74c245f554af | None | None | power off | manageable | False |
 | 275448c1-aa8d-4854-bb3b-bc73e1e1a794 | None | None | power off | manageable | False |
 +--------------------------------------+------+---------------+-------------+--------------------+-------------+</pre>
<p>Run introspection against all managed nodes.</p>
<p>Note: Nodes are booted using ramdisk and their hardware inspected. Introspection prepares nodes for deployment into overcloud.</p>
<pre>[stack@odpd ~]$ openstack overcloud node introspect --all-manageable \
--provide
</pre>
:ET